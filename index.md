<p style="text-align: center;"></p>

***<p style="text-align: center;">DeepSim-Nets: Deep Similarity Networks for Stereo Image Matching</p>***



<p align="center">
  <img width="900" height="400" src="https://user-images.githubusercontent.com/28929267/230093358-41c5f835-079d-4ead-9727-f3e8f927ebb3.png">  
 </p>
 
 # Abstract
 We present three multi-scale similarity learning archi-
tectures, or DeepSim networks. These models learn pixel-
level matching with a contrastive loss and are agnostic to
the geometry of the considered scene. We establish a mid-
dle ground between hybrid and end-to-end approaches by
learning to densely allocate all corresponding pixels of an
epipolar pair at once. Our features are learnt on large im-
age tiles to be expressive and capture the sceneâ€™s wider
context. We also demonstrate that curated sample min-
ing can enhance the overall robustness of the predicted
similarities and improve the performance on radiometri-
cally homogeneous areas. We run experiments on aerial
and satellite datasets. Our DeepSim-Nets outperform the
baseline hybrid approaches and generalize better to un-
seen scene geometries than end-to-end methods. Our flex-
ible architecture can be readily adopted in standard multi-
resolution image matching pipelines

 
